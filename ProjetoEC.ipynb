{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Modelo de Classificação\n",
    "\n",
    "### Projeto realizado por :\n",
    "\n",
    "#### \n",
    "* Cosmin Trandafir - 57101\n",
    "* Martim Baptista - 56323\n",
    "* João Serafim - 56376\n",
    "* Martim Paraíba - 56273\n",
    "***\n",
    "\n",
    "#### Counter de horas I guess :{}\n",
    "\n",
    "* Cosmin Trandafir - 4h\n",
    "* Martim Baptista - \n",
    "* João Serafim - 3h\n",
    "* Martim Paraíba - \n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questoes: \n",
    "- Devemos apagar colunas que possuem demasiados valores a zero?\n",
    "- Devemos normalizar primeiro ou inputar primeiro?\n",
    "- Devemos testar e mostrar os testes de todos os hyperparametros ou apenas os principais?\n",
    "\n",
    "- Devemos testar com IterativeImputer?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neste projeto vamos usar o dataset: ***biodegradable_a.cvs*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpMax_L</th>\n",
       "      <th>J_Dz(e)</th>\n",
       "      <th>nHM</th>\n",
       "      <th>F01</th>\n",
       "      <th>F04</th>\n",
       "      <th>NssssC</th>\n",
       "      <th>nCb</th>\n",
       "      <th>C</th>\n",
       "      <th>nCp</th>\n",
       "      <th>nO</th>\n",
       "      <th>...</th>\n",
       "      <th>C_026</th>\n",
       "      <th>F02_CN</th>\n",
       "      <th>nHDon</th>\n",
       "      <th>SpMax_B</th>\n",
       "      <th>Psi_i_A</th>\n",
       "      <th>nN</th>\n",
       "      <th>SM6_B</th>\n",
       "      <th>nArCOOR</th>\n",
       "      <th>nX</th>\n",
       "      <th>Biodegradable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.919000</td>\n",
       "      <td>2.690900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.400000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.949000</td>\n",
       "      <td>1.591000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.253000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.170000</td>\n",
       "      <td>2.114400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.315000</td>\n",
       "      <td>1.967000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.257000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.932000</td>\n",
       "      <td>3.251200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.700000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.417000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.601000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.709800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.690000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.236000</td>\n",
       "      <td>3.394400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.400000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.351000</td>\n",
       "      <td>2.405000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.003000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4559</th>\n",
       "      <td>4.175650</td>\n",
       "      <td>3.454649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.398382</td>\n",
       "      <td>3.241090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.406748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4560</th>\n",
       "      <td>3.853731</td>\n",
       "      <td>2.747142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.300000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.429148</td>\n",
       "      <td>2.719309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.511511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4561</th>\n",
       "      <td>4.294771</td>\n",
       "      <td>3.471226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.422154</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.351666</td>\n",
       "      <td>2.729456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.699324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4562</th>\n",
       "      <td>4.560376</td>\n",
       "      <td>3.896390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.059198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.908802</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4563</th>\n",
       "      <td>4.045097</td>\n",
       "      <td>2.847185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.386643</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.032224</td>\n",
       "      <td>2.613357</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.863314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4564 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SpMax_L   J_Dz(e)  nHM  F01  F04  NssssC  nCb          C  nCp   nO  \\\n",
       "0     3.919000  2.690900  0.0  0.0  0.0     0.0  0.0  31.400000  2.0  0.0   \n",
       "1     4.170000  2.114400  0.0  0.0  0.0     0.0  0.0  30.800000  1.0  1.0   \n",
       "2     3.932000  3.251200  0.0  0.0  0.0     0.0  0.0  26.700000  2.0  4.0   \n",
       "3     3.000000  2.709800  0.0  0.0  0.0     0.0  0.0  20.000000  NaN  2.0   \n",
       "4     4.236000  3.394400  0.0  0.0  0.0     0.0  0.0  29.400000  2.0  4.0   \n",
       "...        ...       ...  ...  ...  ...     ...  ...        ...  ...  ...   \n",
       "4559  4.175650  3.454649  0.0  0.0  0.0     0.0  0.0  27.300000  2.0  2.0   \n",
       "4560  3.853731  2.747142  0.0  NaN  0.0     0.0  0.0  33.300000  0.0  0.0   \n",
       "4561  4.294771  3.471226  0.0  0.0  0.0     0.0  0.0  28.422154  2.0  2.0   \n",
       "4562  4.560376  3.896390  0.0  0.0  0.0     0.0  0.0        NaN  2.0  3.0   \n",
       "4563  4.045097  2.847185  0.0  0.0  0.0     0.0  0.0  23.386643  1.0  1.0   \n",
       "\n",
       "      ...  C_026  F02_CN  nHDon   SpMax_B   Psi_i_A   nN     SM6_B  nArCOOR  \\\n",
       "0     ...    0.0     0.0    0.0  2.949000  1.591000  0.0  7.253000      0.0   \n",
       "1     ...    0.0     0.0    0.0  3.315000  1.967000  0.0  7.257000      0.0   \n",
       "2     ...    0.0     0.0    1.0       NaN  2.417000  0.0  7.601000      0.0   \n",
       "3     ...    0.0     0.0    1.0       NaN  5.000000  0.0  6.690000      0.0   \n",
       "4     ...    0.0     0.0    0.0  3.351000  2.405000  0.0  8.003000      0.0   \n",
       "...   ...    ...     ...    ...       ...       ...  ...       ...      ...   \n",
       "4559  ...    0.0     0.0    0.0  3.398382  3.241090  0.0  7.406748      0.0   \n",
       "4560  ...    0.0     0.0    1.0  3.429148  2.719309  0.0  7.511511      0.0   \n",
       "4561  ...    0.0     0.0    0.0  3.351666  2.729456  0.0  7.699324      0.0   \n",
       "4562  ...    0.0     0.0    0.0       NaN  3.059198  0.0  7.908802      0.0   \n",
       "4563  ...    0.0     2.0    2.0  3.032224  2.613357  1.0  6.863314      0.0   \n",
       "\n",
       "       nX  Biodegradable  \n",
       "0     0.0             RB  \n",
       "1     0.0             RB  \n",
       "2     0.0             RB  \n",
       "3     0.0             RB  \n",
       "4     NaN             RB  \n",
       "...   ...            ...  \n",
       "4559  0.0             RB  \n",
       "4560  0.0             RB  \n",
       "4561  0.0             RB  \n",
       "4562  0.0             RB  \n",
       "4563  0.0             RB  \n",
       "\n",
       "[4564 rows x 42 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Load biodegradable dataset\n",
    "\n",
    "bio_df = pd.read_csv(\"biodegradable_a.csv\")\n",
    "bio_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic functions and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import impute\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, matthews_corrcoef, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_scores(y_test, y_pred):\n",
    "    # Evaluate the performance of the model using various metrics\n",
    "    print(\"The Precision is: %7.4f\" % precision_score(y_test, y_pred))\n",
    "    print(\"The Recall is: %7.4f\" % recall_score(y_test, y_pred))\n",
    "    print(\"The F1 score is: %7.4f\" % f1_score(y_test, y_pred))\n",
    "    print(\"The Matthews correlation coefficient is: %7.4f\" % matthews_corrcoef(y_test, y_pred))\n",
    "    print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_model(imputer, scaler, classifier, X_train, X_test, y_train):\n",
    "    # Impute missing values\n",
    "    imputer.fit(X_train)\n",
    "    X_train_imputed = imputer.transform(X_train)\n",
    "    X_test_imputed = imputer.transform(X_test)\n",
    "    \n",
    "    \n",
    "    # Scale the test data\n",
    "    scaler.fit(X_train_imputed)\n",
    "    X_train_scaled = scaler.transform(X_train_imputed)\n",
    "    X_test_scaled = scaler.transform(X_test_imputed)\n",
    "    \n",
    "    # Train the classifier\n",
    "    classifier.fit(X_train_scaled, y_train)\n",
    "    preds = classifier.predict(X_test_scaled)\n",
    "    \n",
    "    # Compute evaluation metrics\n",
    "    precision = precision_score(y_test, preds)\n",
    "    recall = recall_score(y_test, preds)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "    mcc = matthews_corrcoef(y_test, preds)\n",
    "    \n",
    "    # Compute cross-validation scores\n",
    "    cv_scores = cross_val_score(classifier, X_test_scaled, y_test, cv=10)\n",
    "    mean_cv_score = cv_scores.mean()\n",
    "    \n",
    "    # Create histogram\n",
    "    labels = ['Precision', 'Recall', 'F1 Score', 'MCC', 'Mean CV Score']\n",
    "    scores = [precision, recall, f1, mcc, mean_cv_score]\n",
    "    plt.bar(labels, scores)\n",
    "    plt.title('Model Evaluation Metrics')\n",
    "    plt.ylim([0.7, 1.0])\n",
    "    plt.grid(axis='y')\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide Freatures and Class columns for preprocessing\n",
    "X = bio_df.iloc[:, :-1]\n",
    "y = bio_df.iloc[:, -1]\n",
    "\n",
    "# Encode string classes to a numeric value for Imputer\n",
    "le = preprocessing.LabelEncoder()\n",
    "df_encoded_classes = le.fit_transform(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Imputation\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Simple Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, df_encoded_classes, test_size=0.33)\n",
    "\n",
    "imputers = [SimpleImputer]\n",
    "for \n",
    "\n",
    "evaluate_model(SimpleImputer(), StandardScaler(), LogisticRegression(max_iter=10000), X_train, X_test, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for: MinMaxScaler\n",
      "Accuracy: 0.9230\n",
      "Precision: 0.9214\n",
      "Recall: 0.9920\n",
      "Confusion Matrix:\n",
      "[[ 149  106]\n",
      " [  10 1242]]\n",
      "\n",
      "Results for: StandardScaler\n",
      "Accuracy: 0.9542\n",
      "Precision: 0.9575\n",
      "Recall: 0.9888\n",
      "Confusion Matrix:\n",
      "[[ 200   55]\n",
      " [  14 1238]]\n",
      "\n",
      "Results for: Normalizer\n",
      "Accuracy: 0.8719\n",
      "Precision: 0.8669\n",
      "Recall: 0.9992\n",
      "Confusion Matrix:\n",
      "[[  63  192]\n",
      " [   1 1251]]\n",
      "\n",
      "Results for: PowerTransformer\n",
      "Accuracy: 0.9396\n",
      "Precision: 0.9490\n",
      "Recall: 0.9800\n",
      "Confusion Matrix:\n",
      "[[ 189   66]\n",
      " [  25 1227]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer, PowerTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# Using a simple imputer TODO use the best\n",
    "simple_imputer = SimpleImputer(strategy = \"median\")\n",
    "df_imputed_simple = simple_imputer.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_imputed_simple, y, test_size=0.33)\n",
    "X_train.shape, X_test.shape\n",
    "\n",
    "scalers = [(MinMaxScaler(),\"MinMaxScaler\"), (StandardScaler(),\"StandardScaler\"), (Normalizer(),\"Normalizer\"), (PowerTransformer(),\"PowerTransformer\")]\n",
    "\n",
    "for scaler,name in scalers:\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    clf = LogisticRegression(max_iter=10000)\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, pos_label='RB')\n",
    "    recall = recall_score(y_test, y_pred, pos_label='RB')\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Results for:\", name)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{cm}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
