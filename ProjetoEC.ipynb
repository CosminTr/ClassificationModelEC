{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Modelo de Classificação\n",
    "\n",
    "### Projeto realizado por :\n",
    "\n",
    "#### \n",
    "* Cosmin Trandafir - 57101\n",
    "* Martim Baptista - 56323\n",
    "* João Serafim - 56376\n",
    "* Martim Paraíba - 56273\n",
    "***\n",
    "\n",
    "#### Counter de horas I guess :{}\n",
    "\n",
    "* Cosmin Trandafir - 4h\n",
    "* Martim Baptista - \n",
    "* João Serafim - 3h\n",
    "* Martim Paraíba - \n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questoes: \n",
    "- Devemos apagar colunas que possuem demasiados valores a zero?\n",
    "- Devemos normalizar primeiro ou inputar primeiro?\n",
    "- Devemos testar e mostrar os testes de todos os hyperparametros ou apenas os principais?\n",
    "\n",
    "- Devemos testar com IterativeImputer?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neste projeto vamos usar o dataset: ***biodegradable_a.cvs*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpMax_L</th>\n",
       "      <th>J_Dz(e)</th>\n",
       "      <th>nHM</th>\n",
       "      <th>F01</th>\n",
       "      <th>F04</th>\n",
       "      <th>NssssC</th>\n",
       "      <th>nCb</th>\n",
       "      <th>C</th>\n",
       "      <th>nCp</th>\n",
       "      <th>nO</th>\n",
       "      <th>...</th>\n",
       "      <th>C_026</th>\n",
       "      <th>F02_CN</th>\n",
       "      <th>nHDon</th>\n",
       "      <th>SpMax_B</th>\n",
       "      <th>Psi_i_A</th>\n",
       "      <th>nN</th>\n",
       "      <th>SM6_B</th>\n",
       "      <th>nArCOOR</th>\n",
       "      <th>nX</th>\n",
       "      <th>Biodegradable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.919000</td>\n",
       "      <td>2.690900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.400000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.949000</td>\n",
       "      <td>1.591000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.253000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.170000</td>\n",
       "      <td>2.114400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.315000</td>\n",
       "      <td>1.967000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.257000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.932000</td>\n",
       "      <td>3.251200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.700000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.417000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.601000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.709800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.690000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.236000</td>\n",
       "      <td>3.394400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.400000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.351000</td>\n",
       "      <td>2.405000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.003000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4559</th>\n",
       "      <td>4.175650</td>\n",
       "      <td>3.454649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.398382</td>\n",
       "      <td>3.241090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.406748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4560</th>\n",
       "      <td>3.853731</td>\n",
       "      <td>2.747142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.300000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.429148</td>\n",
       "      <td>2.719309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.511511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4561</th>\n",
       "      <td>4.294771</td>\n",
       "      <td>3.471226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.422154</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.351666</td>\n",
       "      <td>2.729456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.699324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4562</th>\n",
       "      <td>4.560376</td>\n",
       "      <td>3.896390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.059198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.908802</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4563</th>\n",
       "      <td>4.045097</td>\n",
       "      <td>2.847185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.386643</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.032224</td>\n",
       "      <td>2.613357</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.863314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4564 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SpMax_L   J_Dz(e)  nHM  F01  F04  NssssC  nCb          C  nCp   nO  \\\n",
       "0     3.919000  2.690900  0.0  0.0  0.0     0.0  0.0  31.400000  2.0  0.0   \n",
       "1     4.170000  2.114400  0.0  0.0  0.0     0.0  0.0  30.800000  1.0  1.0   \n",
       "2     3.932000  3.251200  0.0  0.0  0.0     0.0  0.0  26.700000  2.0  4.0   \n",
       "3     3.000000  2.709800  0.0  0.0  0.0     0.0  0.0  20.000000  NaN  2.0   \n",
       "4     4.236000  3.394400  0.0  0.0  0.0     0.0  0.0  29.400000  2.0  4.0   \n",
       "...        ...       ...  ...  ...  ...     ...  ...        ...  ...  ...   \n",
       "4559  4.175650  3.454649  0.0  0.0  0.0     0.0  0.0  27.300000  2.0  2.0   \n",
       "4560  3.853731  2.747142  0.0  NaN  0.0     0.0  0.0  33.300000  0.0  0.0   \n",
       "4561  4.294771  3.471226  0.0  0.0  0.0     0.0  0.0  28.422154  2.0  2.0   \n",
       "4562  4.560376  3.896390  0.0  0.0  0.0     0.0  0.0        NaN  2.0  3.0   \n",
       "4563  4.045097  2.847185  0.0  0.0  0.0     0.0  0.0  23.386643  1.0  1.0   \n",
       "\n",
       "      ...  C_026  F02_CN  nHDon   SpMax_B   Psi_i_A   nN     SM6_B  nArCOOR  \\\n",
       "0     ...    0.0     0.0    0.0  2.949000  1.591000  0.0  7.253000      0.0   \n",
       "1     ...    0.0     0.0    0.0  3.315000  1.967000  0.0  7.257000      0.0   \n",
       "2     ...    0.0     0.0    1.0       NaN  2.417000  0.0  7.601000      0.0   \n",
       "3     ...    0.0     0.0    1.0       NaN  5.000000  0.0  6.690000      0.0   \n",
       "4     ...    0.0     0.0    0.0  3.351000  2.405000  0.0  8.003000      0.0   \n",
       "...   ...    ...     ...    ...       ...       ...  ...       ...      ...   \n",
       "4559  ...    0.0     0.0    0.0  3.398382  3.241090  0.0  7.406748      0.0   \n",
       "4560  ...    0.0     0.0    1.0  3.429148  2.719309  0.0  7.511511      0.0   \n",
       "4561  ...    0.0     0.0    0.0  3.351666  2.729456  0.0  7.699324      0.0   \n",
       "4562  ...    0.0     0.0    0.0       NaN  3.059198  0.0  7.908802      0.0   \n",
       "4563  ...    0.0     2.0    2.0  3.032224  2.613357  1.0  6.863314      0.0   \n",
       "\n",
       "       nX  Biodegradable  \n",
       "0     0.0             RB  \n",
       "1     0.0             RB  \n",
       "2     0.0             RB  \n",
       "3     0.0             RB  \n",
       "4     NaN             RB  \n",
       "...   ...            ...  \n",
       "4559  0.0             RB  \n",
       "4560  0.0             RB  \n",
       "4561  0.0             RB  \n",
       "4562  0.0             RB  \n",
       "4563  0.0             RB  \n",
       "\n",
       "[4564 rows x 42 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Load biodegradable dataset\n",
    "\n",
    "bio_df = pd.read_csv(\"biodegradable_a.csv\")\n",
    "bio_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic functions and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import impute\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runner(scaler, imputer, modeler, X_train, y_train, X_test):\n",
    "    #this is the heavy duty modeler, outputing predictions\n",
    "    imputer.fit(X_train)\n",
    "    Xt_train = imputer.transform(X_train)\n",
    "    Xt_test  = imputer.transform(X_test)\n",
    "    scaler.fit(Xt_train)\n",
    "    Xt_train = scaler.transform(Xt_train)\n",
    "    Xt_test  = scaler.transform(Xt_test)\n",
    "    modeler.fit(Xt_train, y_train)\n",
    "    return modeler.predict(Xt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_scores(y_test, y_pred):\n",
    "    # Evaluate the performance of the model using various metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(\"Accuracy: {:.4f}\".format(accuracy))\n",
    "    print(\"Precision:{:.4f}\".format(precision))\n",
    "    print(\"Recall:{:.4f}\".format(recall))\n",
    "    print(\"F1 score:{:.4f}\".format(f1))\n",
    "    print(\"Confusion matrix:\\n\", confusion_mat)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide Freatures and Class columns for preprocessing\n",
    "X = bio_df.iloc[:, :-1]\n",
    "y = bio_df.iloc[:, -1]\n",
    "\n",
    "# Encode string classes to a numeric value for Imputer\n",
    "le = preprocessing.LabelEncoder()\n",
    "df_encoded_classes = le.fit_transform(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Imputation\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Simple Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Imputer\n",
      "Accuracy: 0.9456\n",
      "Precision:0.9510\n",
      "Recall:0.9857\n",
      "F1 score:0.9680\n",
      "Confusion matrix:\n",
      " [[ 184   64]\n",
      " [  18 1241]]\n",
      "Cross-validation scores: [0.87527352 0.95185996 0.96498906 0.96936543 0.96491228 0.96491228\n",
      " 0.93421053 0.95175439 0.96491228 0.94517544]\n",
      "Average score:0.9487\n",
      "----------------------------------------\n",
      "Now using the median for the imputation\n",
      "----------------------------------------\n",
      "Accuracy: 0.9463\n",
      "Precision:0.9478\n",
      "Recall:0.9905\n",
      "F1 score:0.9687\n",
      "Confusion matrix:\n",
      " [[ 173   69]\n",
      " [  12 1253]]\n",
      "Cross-validation scores: [0.87964989 0.94967177 0.96498906 0.96280088 0.9627193  0.96710526\n",
      " 0.92763158 0.95175439 0.9627193  0.94517544]\n",
      "Average score:0.9474\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"Simple Imputer\")\n",
    "#mean\n",
    "# Replace NaN values with mean value of k-nearest neighbors using KNNImputer\n",
    "simple_imputer = SimpleImputer(strategy = \"mean\")\n",
    "df_imputed_simple = simple_imputer.fit_transform(X)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_imputed_simple, df_encoded_classes, test_size=0.33)\n",
    "\n",
    "# Create a logistic regression model\n",
    "clf = LogisticRegression(max_iter=10000)\n",
    "\n",
    "# Train the model on the training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model using various metrics\n",
    "final_scores(y_test, y_pred)\n",
    "    \n",
    "scores = cross_val_score(clf, df_imputed_simple, df_encoded_classes, cv=10)\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(\"Average score:{:.4f}\".format(scores.mean()))\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Now using the median for the imputation\")\n",
    "print(\"----------------------------------------\")\n",
    "\n",
    "#median\n",
    "# Replace NaN values with mean value of k-nearest neighbors using KNNImputer\n",
    "simple_imputer = SimpleImputer(strategy = \"median\")\n",
    "df_imputed_simple = simple_imputer.fit_transform(X)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_imputed_simple, df_encoded_classes, test_size=0.33)\n",
    "\n",
    "# Create a logistic regression model\n",
    "clf = LogisticRegression(max_iter=10000)\n",
    "\n",
    "# Train the model on the training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model using various metrics\n",
    "final_scores(y_test, y_pred)\n",
    "scores = cross_val_score(clf, df_imputed_simple, df_encoded_classes, cv=10)\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(\"Average score:{:.4f}\".format(scores.mean()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### KNN Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Imputer\n",
      "Accuracy: 0.9562\n",
      "Precision:0.9630\n",
      "Recall:0.9858\n",
      "F1 score:0.9743\n",
      "Confusion matrix:\n",
      " [[ 190   48]\n",
      " [  18 1251]]\n",
      "Cross-validation scores: [0.86870897 0.94967177 0.96280088 0.97155361 0.96491228 0.96929825\n",
      " 0.9254386  0.95833333 0.96491228 0.94736842]\n",
      "Average score:0.9483\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "print(\"KNN Imputer\")\n",
    "# Replace NaN values with mean value of k-nearest neighbors using KNNImputer\n",
    "knn_imputer = KNNImputer()\n",
    "df_imputed_knn = knn_imputer.fit_transform(X)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_imputed_knn, df_encoded_classes, test_size=0.33)\n",
    "\n",
    "# Create a logistic regression model\n",
    "clf = LogisticRegression(max_iter=10000)\n",
    "\n",
    "# Train the model on the training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model using various metrics\n",
    "final_scores(y_test, y_pred)\n",
    "\n",
    "scores = cross_val_score(clf, df_imputed_knn, df_encoded_classes, cv=10)\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(\"Average score:{:.4f}\".format(scores.mean()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Iterative Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterative Imputer\n",
      "Accuracy: 0.9489\n",
      "Precision:0.9530\n",
      "Recall:0.9872\n",
      "F1 score:0.9698\n",
      "Confusion matrix:\n",
      " [[ 192   61]\n",
      " [  16 1238]]\n",
      "Cross-validation scores: [0.87089716 0.94967177 0.96061269 0.97155361 0.9627193  0.96710526\n",
      " 0.92105263 0.95833333 0.96491228 0.94517544]\n",
      "Average score:0.9472\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "print(\"Iterative Imputer\")\n",
    "# Replace NaN values with mean value of k-nearest neighbors using KNNImputer\n",
    "iter_imputer = IterativeImputer(random_state = 0)\n",
    "df_imputed_iter = iter_imputer.fit_transform(X)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_imputed_iter, df_encoded_classes, test_size=0.33)\n",
    "\n",
    "# Create a logistic regression model\n",
    "clf = LogisticRegression(max_iter=10000)\n",
    "\n",
    "# Train the model on the training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model using various metrics\n",
    "final_scores(y_test, y_pred)\n",
    "\n",
    "scores = cross_val_score(clf, df_imputed_iter, df_encoded_classes, cv=10)\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(\"Average score:{:.4f}\".format(scores.mean()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for: MinMaxScaler\n",
      "Accuracy: 0.9589\n",
      "Precision: 0.9711\n",
      "Recall: 0.9803\n",
      "Confusion Matrix:\n",
      "[[ 203   37]\n",
      " [  25 1242]]\n",
      "\n",
      "Results for: StandardScaler\n",
      "Accuracy: 0.9529\n",
      "Precision: 0.9709\n",
      "Recall: 0.9732\n",
      "Confusion Matrix:\n",
      "[[ 203   37]\n",
      " [  34 1233]]\n",
      "\n",
      "Results for: Normalizer\n",
      "Accuracy: 0.9542\n",
      "Precision: 0.9731\n",
      "Recall: 0.9724\n",
      "Confusion Matrix:\n",
      "[[ 206   34]\n",
      " [  35 1232]]\n",
      "\n",
      "Results for: PowerTransformer\n",
      "Accuracy: 0.9536\n",
      "Precision: 0.9679\n",
      "Recall: 0.9771\n",
      "Confusion Matrix:\n",
      "[[ 199   41]\n",
      " [  29 1238]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer, PowerTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# Using a simple imputer TODO use the best\n",
    "simple_imputer = SimpleImputer(strategy = \"median\")\n",
    "df_imputed_simple = simple_imputer.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_imputed_simple, y, test_size=0.33)\n",
    "X_train.shape, X_test.shape\n",
    "\n",
    "scalers = [(MinMaxScaler(),\"MinMaxScaler\"), (StandardScaler(),\"StandardScaler\"), (Normalizer(),\"Normalizer\"), (PowerTransformer(),\"PowerTransformer\")]\n",
    "\n",
    "for scaler,name in scalers:\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, pos_label='RB')\n",
    "    recall = recall_score(y_test, y_pred, pos_label='RB')\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Results for:\", name)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{cm}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import explained_variance_score, mean_squared_error\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "def model_testing(X_train, X_test, y_train, y_test, feature_selection=None):\n",
    "    # select top 5 most correlated variables with y, if feature_selection is not None\n",
    "    if feature_selection == 'correlation':\n",
    "        corr_matrix = np.corrcoef(np.hstack((y_train.reshape((len(y_train), 1)), X_train)).T)\n",
    "        corr_with_y = corr_matrix[0, 1:]\n",
    "        correlationli = list(corr_with_y)\n",
    "        sorted_indices = sorted(range(len(correlationli)), key=lambda k: correlationli[k], reverse=True)\n",
    "        top5 = sorted_indices[:5]\n",
    "        print(\"Top 5 by correlation:\", top5)\n",
    "        X_train = X_train[:, top5]\n",
    "        X_test = X_test[:, top5]\n",
    "\n",
    "    # train models\n",
    "    dtr = DecisionTreeRegressor(max_depth=5)\n",
    "    dtr.fit(X_train, y_train)\n",
    "\n",
    "    lmr = LinearRegression()\n",
    "    lmr.fit(X_train, y_train)\n",
    "\n",
    "    # evaluate models\n",
    "    dt_preds = dtr.predict(X_test)\n",
    "    lr_preds = lmr.predict(X_test)\n",
    "\n",
    "    print(\"RVE DTs: %7.4f\" % explained_variance_score(y_test, dt_preds))\n",
    "    print(\"RVE LRs: %7.4f\" % explained_variance_score(y_test, lr_preds))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Using all variables------\n",
      "RVE DTs:  0.5790\n",
      "RVE LRs:  0.5238\n",
      "------Using the top5------\n",
      "Top 5 by correlation: [13, 17, 9, 30, 36]\n",
      "RVE DTs:  0.1669\n",
      "RVE LRs:  0.0758\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_imputed_simple, df_encoded_classes, test_size=0.33)\n",
    "    \n",
    "# use all variables\n",
    "print(\"------Using all variables------\")\n",
    "model_testing(X_train, X_test, y_train, y_test)\n",
    "print(\"------Using the top5------\")\n",
    "# use top 5 most correlated variables\n",
    "model_testing(X_train, X_test, y_train, y_test, feature_selection='correlation')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stepwise - Forward and Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features selected are columns:  [ 2  5 19 21 33]\n",
      "RVE DTs:  0.5559\n",
      "RVE LRs:  0.4579\n",
      "Decision tree: Forward\n",
      "The features selected are columns:  [ 2  5 11 29 33]\n",
      "RVE DTs:  0.5902\n",
      "RVE LRs:  0.4277\n",
      "Decision tree: Backward\n",
      "The features selected are columns:  [ 2  5 10 11 21]\n",
      "RVE DTs:  0.5684\n",
      "RVE LRs:  0.4298\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "N,M=X_train.shape\n",
    "#LR\n",
    "lmr=LinearRegression()\n",
    "sfs = SequentialFeatureSelector(lmr, n_features_to_select=5)\n",
    "sfs.fit(X_train, y_train)\n",
    "\n",
    "#get the relevant columns\n",
    "features=sfs.get_support()\n",
    "Features_selected =np.arange(M)[features]\n",
    "print(\"The features selected are columns: \", Features_selected)\n",
    "\n",
    "nX_train=sfs.transform(X_train)\n",
    "nX_test=sfs.transform(X_test)\n",
    "\n",
    "model_testing(nX_train, nX_test, y_train, y_test)\n",
    "#--------------------------------------------------------------------\n",
    "#DT Forward\n",
    "dtr = DecisionTreeRegressor(max_depth=3)\n",
    "sfs = SequentialFeatureSelector(dtr, n_features_to_select=5, direction=\"forward\")\n",
    "sfs.fit(X_train, y_train)\n",
    "\n",
    "#get the relevant columns\n",
    "features=sfs.get_support()\n",
    "Features_selected =np.arange(M)[features]\n",
    "print(\"Decision tree: Forward\")\n",
    "print(\"The features selected are columns: \", Features_selected)\n",
    "\n",
    "nX_train=sfs.transform(X_train)\n",
    "nX_test=sfs.transform(X_test)\n",
    "\n",
    "model_testing(nX_train, nX_test, y_train, y_test)\n",
    "#-------------------------------------------------------------------- takes a bit longer\n",
    "#DT backward\n",
    "dtr = DecisionTreeRegressor(max_depth=3)\n",
    "sfs = SequentialFeatureSelector(dtr, n_features_to_select=5, direction=\"backward\")\n",
    "sfs.fit(X_train, y_train)\n",
    "\n",
    "#get the relevant columns\n",
    "features=sfs.get_support()\n",
    "Features_selected =np.arange(M)[features]\n",
    "print(\"Decision tree: Backward\")\n",
    "print(\"The features selected are columns: \", Features_selected)\n",
    "\n",
    "nX_train=sfs.transform(X_train)\n",
    "nX_test=sfs.transform(X_test)\n",
    "\n",
    "model_testing(nX_train, nX_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
