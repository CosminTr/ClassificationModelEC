{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Modelo de Classificação\n",
    "\n",
    "### Projeto realizado por :\n",
    "\n",
    "#### \n",
    "* Cosmin Trandafir - 57101\n",
    "* Martim Baptista - 56323\n",
    "* João Serafim - 56376\n",
    "* Martim Paraíba - 56273\n",
    "***\n",
    "\n",
    "#### Counter de horas I guess :{}\n",
    "\n",
    "* Cosmin Trandafir - 4h\n",
    "* Martim Baptista - \n",
    "* João Serafim - 3h\n",
    "* Martim Paraíba - \n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questoes: \n",
    "- Devemos apagar colunas que possuem demasiados valores a zero?\n",
    "- Devemos testar e mostrar os testes de todos os hyperparametros ou apenas os principais?\n",
    "- Diferentes resultados de melhor imputer aparecem. Qual devemos confiar?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neste projeto vamos usar o dataset: ***biodegradable_a.cvs*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Load biodegradable dataset\n",
    "\n",
    "bio_df = pd.read_csv(\"biodegradable_a.csv\")\n",
    "bio_df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic functions and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer, PowerTransformer\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, matthews_corrcoef, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_scores(y_test, y_pred):\n",
    "    # Evaluate the performance of the model using various metrics\n",
    "    print(\"The Precision is: %7.4f\" % precision_score(y_test, y_pred))\n",
    "    print(\"The Recall is: %7.4f\" % recall_score(y_test, y_pred))\n",
    "    print(\"The F1 score is: %7.4f\" % f1_score(y_test, y_pred))\n",
    "    print(\"The Matthews correlation coefficient is: %7.4f\" % matthews_corrcoef(y_test, y_pred))\n",
    "    print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Returns mean crossvalidation score\n",
    "def evaluate_model(imputer_tuple, scaler_tuple, classifier, X_train, X_test, y_train):\n",
    "    imputer = imputer_tuple[1]\n",
    "    # Impute missing values\n",
    "    imputer.fit(X_train)\n",
    "    X_train_imputed = imputer.transform(X_train)\n",
    "    X_test_imputed = imputer.transform(X_test)\n",
    "    \n",
    "    scaler = scaler_tuple[1]\n",
    "    # Scale the test data\n",
    "    scaler.fit(X_train_imputed)\n",
    "    X_train_scaled = scaler.transform(X_train_imputed)\n",
    "    X_test_scaled = scaler.transform(X_test_imputed)\n",
    "    \n",
    "    # Train the classifier\n",
    "    classifier.fit(X_train_scaled, y_train)\n",
    "    preds = classifier.predict(X_test_scaled)\n",
    "    \n",
    "    # Compute evaluation metrics for plot\n",
    "    precision = precision_score(y_test, preds)\n",
    "    recall = recall_score(y_test, preds)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "    mcc = matthews_corrcoef(y_test, preds)\n",
    "    \n",
    "    # Compute cross-validation scores\n",
    "    cv_scores = cross_val_score(classifier, X_test_scaled, y_test, cv=10)\n",
    "    mean_cv_score = cv_scores.mean()\n",
    "    \n",
    "    # Print classificatiom metric scores\n",
    "    print(\"Imputer: {} \\nScaler: {}\\nCrossValidationScore: {:.6f}\\n\".format(imputer_tuple[0], scaler_tuple[0], mean_cv_score))\n",
    "    classification_scores(y_test, preds)\n",
    "    \n",
    "    return f1\n",
    "\n",
    "\n",
    "    \"\"\"  # Create histogram\n",
    "    labels = ['Precision', 'Recall', 'F1 Score', 'MCC', 'Mean CV Score']\n",
    "    scores = [precision, recall, f1, mcc, mean_cv_score]\n",
    "    plt.bar(labels, scores)\n",
    "    plt.title('Model Evaluation Metrics')\n",
    "    plt.ylim([0.7, 1.0])\n",
    "    plt.grid(axis='y')\n",
    "    plt.show() \"\"\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "# Divide Freatures and Class columns for preprocessing\n",
    "X = bio_df.iloc[:, :-1]\n",
    "y = bio_df.iloc[:, -1]\n",
    "\n",
    "# Encode string classes to a numeric value for Imputer\n",
    "le = preprocessing.LabelEncoder()\n",
    "df_encoded_classes = le.fit_transform(y)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Imputation\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Combinations of \n",
    "#### Imputers: \n",
    "- SimpleImputer with mean strategy\n",
    "- SimpleImputer with median strategy\n",
    "- KNNImputer with 3 nearest neighbors\n",
    "- KNNImputer with 5 nearest neighbors\n",
    "- (Maybe put KNN =7)\n",
    "- KNNImputer with 9 nearest neighbors\n",
    "- KNNImputer with 11 nearest neighbors\n",
    "- IterativeImputer\n",
    "\n",
    "#### With Scalers:\n",
    "- MinMaxScaler\n",
    "- StandardScaler\n",
    "- Normalizer\n",
    "- PowerTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, df_encoded_classes, test_size=0.33, random_state=0)\n",
    "\n",
    "# List of imputers to test (imputer_name, imputer)\n",
    "imputers =[(\"SimpleImputer = mean\", SimpleImputer(strategy='mean')), \n",
    "           (\"SimpleImputer = median\", SimpleImputer(strategy='median')), \n",
    "           (\"KNNImputer 3\",KNNImputer(n_neighbors=3)), \n",
    "           (\"KNNImputer 5\",KNNImputer(n_neighbors=5)), \n",
    "           (\"KNNImputer 9\",KNNImputer(n_neighbors=9)),\n",
    "           (\"KNNImputer 11\",KNNImputer(n_neighbors=11)),\n",
    "           # random state to use same iteration for different runs\n",
    "           (\"IterativeImputer\",IterativeImputer(random_state=0))]\n",
    "\n",
    "# List of scalers to test (scaler_name, scaler)\n",
    "scalers = [(\"MinMaxScaler\",MinMaxScaler()), \n",
    "           (\"StandarScaler\",StandardScaler()), \n",
    "           (\"Normalizer\",Normalizer()), \n",
    "           (\"PowerTransformer\",PowerTransformer())]\n",
    "\n",
    "# List of combinations of imputer and scaler names to user in graph\n",
    "combos = [imputer_name + \" + \" + scaler_name for imputer_name, imputer in imputers for scaler_name, scaler in scalers]\n",
    "\n",
    "# List of mean cross validation scores for every combination of imputers and scalers\n",
    "scores = []\n",
    "\n",
    "for imputer in imputers:\n",
    "    for scaler in scalers:\n",
    "        # Storing scores in list\n",
    "        # random state to use same iteration for different runs\n",
    "        scores.append(evaluate_model(imputer, scaler, LogisticRegression(max_iter=10000, random_state=0), X_train, X_test, y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figsize to adjust size \n",
    "fig, ax = plt.subplots(figsize=(20, 13))\n",
    "ax.bar(combos, scores)\n",
    "ax.set_title('F1 Scores')\n",
    "\n",
    "# Set boundries for y axis \n",
    "ax.set_ylim([0.8, 1.0])\n",
    "ax.grid(axis='y')\n",
    "\n",
    "# Make labels visible\n",
    "ax.set_xticklabels(combos, rotation=90, ha='center')\n",
    "\n",
    "# Calculate and show line of max score\n",
    "max_score_idx = np.argmax(scores)\n",
    "highest_name, highest_score = combos[max_score_idx], scores[max_score_idx]\n",
    "ax.axhline(y=scores[max_score_idx], color='r', linestyle='--', label='Max score')\n",
    "\n",
    "ax.legend([f'Max score: {highest_name}: {highest_score:.4f}'])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Prepare dataset using best Imputer and Scaler\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df_encoded_classes, test_size=0.33, random_state=42)\n",
    "\n",
    "# Impute missing values\n",
    "imputer = IterativeImputer(random_state=0)\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Pearson Correlation between each feature and target classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection using Pearson correlation\n",
    "corr_coef = np.corrcoef(np.hstack((y_train.reshape((-1, 1)), X_train_scaled)).T)\n",
    "corr_features_idx = np.where(corr_coef[0, 1:] > 0)[0]\n",
    "X_train_corr = X_train_scaled[:, corr_features_idx]\n",
    "X_test_corr = X_test_scaled[:, corr_features_idx]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Feature selection using PCA\n",
    "pca = PCA(n_components=41)\n",
    "pca.fit(X_train_scaled)\n",
    "X_train_pca = pca.transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "tve=0 #total variance explained\n",
    "for i, ve in enumerate(pca.explained_variance_ratio_):\n",
    "    tve+=ve\n",
    "    print(\"PC%d - Variance explained: %7.4f - Total Variance: %7.4f\" % (i, ve, tve) )\n",
    "\n",
    "\n",
    "# Define the range of number of components to test\n",
    "n_components_range = range(1, 41)\n",
    "\n",
    "# Evaluate the models using logistic regression with F1 score\n",
    "lr = LogisticRegression(random_state=42)\n",
    "f1_scores = []\n",
    "for n_components in n_components_range:\n",
    "    # Feature selection using PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(X_train_scaled)\n",
    "    X_train_pca = pca.transform(X_train_scaled)\n",
    "    X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "    lr.fit(X_train_pca, y_train)\n",
    "    y_pred = lr.predict(X_test_pca)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    f1_scores.append(f1)\n",
    "    \n",
    "# Find the best value of n_components based on F1 score\n",
    "best_n_components = n_components_range[np.argmax(f1_scores)]\n",
    "\n",
    "# Plot the results\n",
    "plt.plot(n_components_range, f1_scores)\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('F1 score')\n",
    "plt.title('PCA feature selection')\n",
    "plt.axvline(best_n_components, linestyle='--', color='r', label=f'Best n_components={best_n_components}')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Feature selection using PCA with optimal value of components\n",
    "pca = PCA(n_components=n_components)\n",
    "pca.fit(X_train_scaled)\n",
    "X_train_pca = pca.transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# Number of features to select\n",
    "n_best = best_n_components"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature selection using SelectKBest with F-test\n",
    "k = n_best\n",
    "selector = SelectKBest(f_classif, k=k)\n",
    "selector.fit(X_train_scaled, y_train)\n",
    "X_train_kbest = selector.transform(X_train_scaled)\n",
    "X_test_kbest = selector.transform(X_test_scaled)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### SequentialFeatureSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection using Sequential Feature Selector\n",
    "n_features = n_best\n",
    "sfs = SequentialFeatureSelector(LogisticRegression(random_state=42, max_iter=10000),\n",
    "                                n_features_to_select=n_features,\n",
    "                                direction='backward',\n",
    "                                scoring='f1',\n",
    "                                cv=5)\n",
    "sfs.fit(X_train_scaled, y_train)\n",
    "X_train_sfs = sfs.transform(X_train_scaled)\n",
    "X_test_sfs = sfs.transform(X_test_scaled)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Putting it all together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the models using logistic regression with F1 score\n",
    "lr = LogisticRegression(random_state=42)\n",
    "models = [(\"Pearson\", X_train_corr, X_test_corr),\n",
    "          (\"PCA\", X_train_pca, X_test_pca),\n",
    "          (\"SelectKBest\", X_train_kbest, X_test_kbest),\n",
    "          (\"SequentialFeatureSelection\", X_train_sfs, X_test_sfs)]\n",
    "\n",
    "print(f'{n_best} features')\n",
    "for name, X_train_fs, X_test_fs in models:\n",
    "    lr.fit(X_train_fs, y_train)\n",
    "    y_pred = lr.predict(X_test_fs)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(f\"{name} with: F1 score = {f1:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Now onto selecting the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Best Imputer, Scaler and Selector \n",
    "imputer = IterativeImputer(random_state=42)\n",
    "scaler = StandardScaler()\n",
    "selector = SelectKBest(f_classif, k=22)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df_encoded_classes, test_size=0.33, random_state=42)\n",
    "\n",
    "# Impute missing values\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Scale features\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n",
    "\n",
    "# Feature selection using SelectKBest with F-test\n",
    "selector.fit(X_train_scaled, y_train)\n",
    "X_train_kbest = selector.transform(X_train_scaled)\n",
    "X_test_kbest = selector.transform(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define decision tree classifier\n",
    "dtc = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Define grid of hyperparameters to test\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [2, 4, 6, 8, 10],\n",
    "    'min_samples_split': [2, 4, 6, 8, 10],\n",
    "    'min_samples_leaf': [1, 2, 3, 4, 5]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "cv = GridSearchCV(dtc, param_grid=param_grid, scoring='f1', cv=5)\n",
    "cv.fit(X_train_kbest, y_train)\n",
    "\n",
    "# Print the best hyperparameters and performance score\n",
    "print(\"Best hyperparameters:\", cv.best_params_)\n",
    "print(\"Best F1 score:\", cv.best_score_)\n",
    "\n",
    "# Evaluate the model with best hyperparameters on the test set\n",
    "y_pred = cv.predict(X_test_kbest)\n",
    "\n",
    "# Check classification scores\n",
    "classification_scores(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# create a Random Forest classifier object\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# create a GridSearchCV object\n",
    "grid_search = GridSearchCV(rfc, param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train_kbest, y_train)\n",
    "\n",
    "# print the best hyperparameters found by GridSearchCV\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# make predictions on the test set using the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test_kbest)\n",
    "\n",
    "# Check classification scores\n",
    "classification_scores(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SVC classifier\n",
    "svc = SVC(random_state=42)\n",
    "\n",
    "# define the parameter grid to search over\n",
    "gammas = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "Cs = [0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "param_grid = {\"gamma\": gammas, \"C\": Cs}\n",
    "\n",
    "# fit the GridSearchCV object to the training data\n",
    "grid_search = GridSearchCV(svc, param_grid, cv=5, scoring=\"f1\")\n",
    "grid_search = grid_search.fit(X_train_kbest, y_train)\n",
    "\n",
    "# print the best hyperparameters found by GridSearchCV\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# make predictions on the test set using the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test_kbest)\n",
    "\n",
    "# Check classification scores\n",
    "classification_scores(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define classifiers\n",
    "classifiers = [('Decision Tree', DecisionTreeClassifier(criterion='gini', max_depth=8, min_samples_leaf=5, min_samples_split=2, random_state=42)),\n",
    "               ('Random Forest', RandomForestClassifier(max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=50, random_state=42)),\n",
    "               ('SVM', SVC(C=10, gamma=0.1, random_state=42)),\n",
    "               ('Logistic Regression', LogisticRegression(random_state=42))]\n",
    "\n",
    "# evaluate classifiers using precision, recall, f1, and MCC metrics\n",
    "metrics = ['Precision', 'Recall', 'F1', 'MCC']\n",
    "results = pd.DataFrame(columns=metrics, index=[name for name, clf in classifiers])\n",
    "\n",
    "for name, clf in classifiers:\n",
    "    clf.fit(X_train_kbest, y_train)\n",
    "    y_pred = clf.predict(X_test_kbest)\n",
    "    results.loc[name, 'Precision'] = precision_score(y_test, y_pred)\n",
    "    results.loc[name, 'Recall'] = recall_score(y_test, y_pred)\n",
    "    results.loc[name, 'F1'] = f1_score(y_test, y_pred)\n",
    "    results.loc[name, 'MCC'] = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "# plot results\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "results.plot(kind='bar', ax=ax)\n",
    "ax.set_ylim([0.8, 1.0])\n",
    "ax.set_xlabel('Classifier')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Classification Metrics')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n",
    "\n",
    "# print best classifier and its F1 score\n",
    "results['F1'] = results['F1'].astype(float)\n",
    "best_classifier = results['F1'].idxmax()\n",
    "best_score = results.loc[best_classifier, 'F1']\n",
    "print(f'The best classifier is {best_classifier}, with the F1 score of {best_score:.5f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
