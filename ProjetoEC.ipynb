{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Modelo de Classificação\n",
    "\n",
    "### Projeto realizado por :\n",
    "\n",
    "#### \n",
    "* Cosmin Trandafir - 57101\n",
    "* Martim Baptista - 56323\n",
    "* João Serafim - 56376\n",
    "* Martim Paraíba - 56273\n",
    "***\n",
    "\n",
    "#### Counter de horas I guess :{}\n",
    "\n",
    "* Cosmin Trandafir - 4h\n",
    "* Martim Baptista - \n",
    "* João Serafim - 3h\n",
    "* Martim Paraíba - \n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questoes: \n",
    "- Devemos apagar colunas que possuem demasiados valores a zero?\n",
    "- Devemos normalizar primeiro ou inputar primeiro?\n",
    "- Devemos testar e mostrar os testes de todos os hyperparametros ou apenas os principais?\n",
    "\n",
    "- Devemos testar com IterativeImputer?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neste projeto vamos usar o dataset: ***biodegradable_a.cvs*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpMax_L</th>\n",
       "      <th>J_Dz(e)</th>\n",
       "      <th>nHM</th>\n",
       "      <th>F01</th>\n",
       "      <th>F04</th>\n",
       "      <th>NssssC</th>\n",
       "      <th>nCb</th>\n",
       "      <th>C</th>\n",
       "      <th>nCp</th>\n",
       "      <th>nO</th>\n",
       "      <th>...</th>\n",
       "      <th>C_026</th>\n",
       "      <th>F02_CN</th>\n",
       "      <th>nHDon</th>\n",
       "      <th>SpMax_B</th>\n",
       "      <th>Psi_i_A</th>\n",
       "      <th>nN</th>\n",
       "      <th>SM6_B</th>\n",
       "      <th>nArCOOR</th>\n",
       "      <th>nX</th>\n",
       "      <th>Biodegradable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.919000</td>\n",
       "      <td>2.690900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.400000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.949000</td>\n",
       "      <td>1.591000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.253000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.170000</td>\n",
       "      <td>2.114400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.315000</td>\n",
       "      <td>1.967000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.257000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.932000</td>\n",
       "      <td>3.251200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.700000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.417000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.601000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.709800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.690000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.236000</td>\n",
       "      <td>3.394400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.400000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.351000</td>\n",
       "      <td>2.405000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.003000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4559</th>\n",
       "      <td>4.175650</td>\n",
       "      <td>3.454649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.398382</td>\n",
       "      <td>3.241090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.406748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4560</th>\n",
       "      <td>3.853731</td>\n",
       "      <td>2.747142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.300000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.429148</td>\n",
       "      <td>2.719309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.511511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4561</th>\n",
       "      <td>4.294771</td>\n",
       "      <td>3.471226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.422154</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.351666</td>\n",
       "      <td>2.729456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.699324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4562</th>\n",
       "      <td>4.560376</td>\n",
       "      <td>3.896390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.059198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.908802</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4563</th>\n",
       "      <td>4.045097</td>\n",
       "      <td>2.847185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.386643</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.032224</td>\n",
       "      <td>2.613357</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.863314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4564 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SpMax_L   J_Dz(e)  nHM  F01  F04  NssssC  nCb          C  nCp   nO  \\\n",
       "0     3.919000  2.690900  0.0  0.0  0.0     0.0  0.0  31.400000  2.0  0.0   \n",
       "1     4.170000  2.114400  0.0  0.0  0.0     0.0  0.0  30.800000  1.0  1.0   \n",
       "2     3.932000  3.251200  0.0  0.0  0.0     0.0  0.0  26.700000  2.0  4.0   \n",
       "3     3.000000  2.709800  0.0  0.0  0.0     0.0  0.0  20.000000  NaN  2.0   \n",
       "4     4.236000  3.394400  0.0  0.0  0.0     0.0  0.0  29.400000  2.0  4.0   \n",
       "...        ...       ...  ...  ...  ...     ...  ...        ...  ...  ...   \n",
       "4559  4.175650  3.454649  0.0  0.0  0.0     0.0  0.0  27.300000  2.0  2.0   \n",
       "4560  3.853731  2.747142  0.0  NaN  0.0     0.0  0.0  33.300000  0.0  0.0   \n",
       "4561  4.294771  3.471226  0.0  0.0  0.0     0.0  0.0  28.422154  2.0  2.0   \n",
       "4562  4.560376  3.896390  0.0  0.0  0.0     0.0  0.0        NaN  2.0  3.0   \n",
       "4563  4.045097  2.847185  0.0  0.0  0.0     0.0  0.0  23.386643  1.0  1.0   \n",
       "\n",
       "      ...  C_026  F02_CN  nHDon   SpMax_B   Psi_i_A   nN     SM6_B  nArCOOR  \\\n",
       "0     ...    0.0     0.0    0.0  2.949000  1.591000  0.0  7.253000      0.0   \n",
       "1     ...    0.0     0.0    0.0  3.315000  1.967000  0.0  7.257000      0.0   \n",
       "2     ...    0.0     0.0    1.0       NaN  2.417000  0.0  7.601000      0.0   \n",
       "3     ...    0.0     0.0    1.0       NaN  5.000000  0.0  6.690000      0.0   \n",
       "4     ...    0.0     0.0    0.0  3.351000  2.405000  0.0  8.003000      0.0   \n",
       "...   ...    ...     ...    ...       ...       ...  ...       ...      ...   \n",
       "4559  ...    0.0     0.0    0.0  3.398382  3.241090  0.0  7.406748      0.0   \n",
       "4560  ...    0.0     0.0    1.0  3.429148  2.719309  0.0  7.511511      0.0   \n",
       "4561  ...    0.0     0.0    0.0  3.351666  2.729456  0.0  7.699324      0.0   \n",
       "4562  ...    0.0     0.0    0.0       NaN  3.059198  0.0  7.908802      0.0   \n",
       "4563  ...    0.0     2.0    2.0  3.032224  2.613357  1.0  6.863314      0.0   \n",
       "\n",
       "       nX  Biodegradable  \n",
       "0     0.0             RB  \n",
       "1     0.0             RB  \n",
       "2     0.0             RB  \n",
       "3     0.0             RB  \n",
       "4     NaN             RB  \n",
       "...   ...            ...  \n",
       "4559  0.0             RB  \n",
       "4560  0.0             RB  \n",
       "4561  0.0             RB  \n",
       "4562  0.0             RB  \n",
       "4563  0.0             RB  \n",
       "\n",
       "[4564 rows x 42 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Load biodegradable dataset\n",
    "\n",
    "bio_df = pd.read_csv(\"biodegradable_a.csv\")\n",
    "bio_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic functions and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import impute\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, matthews_corrcoef, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_scores(y_test, y_pred):\n",
    "    # Evaluate the performance of the model using various metrics\n",
    "    print(\"The Precision is: %7.4f\" % precision_score(y_test, y_pred))\n",
    "    print(\"The Recall is: %7.4f\" % recall_score(y_test, y_pred))\n",
    "    print(\"The F1 score is: %7.4f\" % f1_score(y_test, y_pred))\n",
    "    print(\"The Matthews correlation coefficient is: %7.4f\" % matthews_corrcoef(y_test, y_pred))\n",
    "    print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_model(imputer, scaler, classifier, X_train, X_test, y_train):\n",
    "    # Impute missing values\n",
    "    imputer.fit(X_train)\n",
    "    X_train_imputed = imputer.transform(X_train)\n",
    "    X_test_imputed = imputer.transform(X_test)\n",
    "    \n",
    "    \n",
    "    # Scale the test data\n",
    "    scaler.fit(X_train_imputed)\n",
    "    X_train_scaled = scaler.transform(X_train_imputed)\n",
    "    X_test_scaled = scaler.transform(X_test_imputed)\n",
    "    \n",
    "    # Train the classifier\n",
    "    classifier.fit(X_train_scaled, y_train)\n",
    "    preds = classifier.predict(X_test_scaled)\n",
    "    \n",
    "    # Compute evaluation metrics\n",
    "    precision = precision_score(y_test, preds)\n",
    "    recall = recall_score(y_test, preds)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "    mcc = matthews_corrcoef(y_test, preds)\n",
    "    \n",
    "    # Compute cross-validation scores\n",
    "    cv_scores = cross_val_score(classifier, X_test_scaled, y_test, cv=10)\n",
    "    mean_cv_score = cv_scores.mean()\n",
    "    \n",
    "    # Create histogram\n",
    "    labels = ['Precision', 'Recall', 'F1 Score', 'MCC', 'Mean CV Score']\n",
    "    scores = [precision, recall, f1, mcc, mean_cv_score]\n",
    "    plt.bar(labels, scores)\n",
    "    plt.title('Model Evaluation Metrics')\n",
    "    plt.ylim([0.7, 1.0])\n",
    "    plt.grid(axis='y')\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide Freatures and Class columns for preprocessing\n",
    "X = bio_df.iloc[:, :-1]\n",
    "y = bio_df.iloc[:, -1]\n",
    "\n",
    "# Encode string classes to a numeric value for Imputer\n",
    "le = preprocessing.LabelEncoder()\n",
    "df_encoded_classes = le.fit_transform(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Imputation\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Simple Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, df_encoded_classes, test_size=0.33)\n",
    "\n",
    "imputers = [SimpleImputer]\n",
    "for \n",
    "\n",
    "evaluate_model(SimpleImputer(), StandardScaler(), LogisticRegression(max_iter=10000), X_train, X_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Precision is:  0.9570\n",
      "The Recall is:  0.9887\n",
      "The F1 score is:  0.9726\n",
      "The Matthews correlation coefficient is:  0.8376\n",
      "Confusion matrix:\n",
      " [[ 213   55]\n",
      " [  14 1225]]\n",
      "Cross-validation scores: [0.87527352 0.95185996 0.96498906 0.96936543 0.96491228 0.96491228\n",
      " 0.93421053 0.95175439 0.96491228 0.94517544]\n",
      "Average score:0.9487\n",
      "----------------------------------------\n",
      "Now using the median for the imputation\n",
      "----------------------------------------\n",
      "The Precision is:  0.9489\n",
      "The Recall is:  0.9881\n",
      "The F1 score is:  0.9681\n",
      "The Matthews correlation coefficient is:  0.7914\n",
      "Confusion matrix:\n",
      " [[ 181   67]\n",
      " [  15 1244]]\n",
      "Cross-validation scores: [0.87964989 0.94967177 0.96498906 0.96280088 0.9627193  0.96710526\n",
      " 0.92763158 0.95175439 0.9627193  0.94517544]\n",
      "Average score:0.9474\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "#mean\n",
    "# Replace NaN values with mean value of k-nearest neighbors using KNNImputer\n",
    "simple_imputer = SimpleImputer(strategy = \"mean\")\n",
    "df_imputed_simple = simple_imputer.fit_transform(X)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_imputed_simple, df_encoded_classes, test_size=0.33)\n",
    "\n",
    "# Create a logistic regression model\n",
    "clf = LogisticRegression(max_iter=10000)\n",
    "\n",
    "# Train the model on the training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model using various metrics\n",
    "classification_scores(y_test, y_pred)\n",
    "    \n",
    "scores = cross_val_score(clf, df_imputed_simple, df_encoded_classes, cv=10)\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(\"Average score:{:.4f}\".format(scores.mean()))\n",
    "\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Now using the median for the imputation\")\n",
    "print(\"----------------------------------------\")\n",
    "\n",
    "#median\n",
    "# Replace NaN values with mean value of k-nearest neighbors using KNNImputer\n",
    "simple_imputer = SimpleImputer(strategy = \"median\")\n",
    "df_imputed_simple = simple_imputer.fit_transform(X)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_imputed_simple, df_encoded_classes, test_size=0.33)\n",
    "\n",
    "# Create a logistic regression model\n",
    "clf = LogisticRegression(max_iter=10000)\n",
    "\n",
    "# Train the model on the training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model using various metrics\n",
    "classification_scores(y_test, y_pred)\n",
    "scores = cross_val_score(clf, df_imputed_simple, df_encoded_classes, cv=10)\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(\"Average score:{:.4f}\".format(scores.mean()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### KNN Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Precision is:  0.9578\n",
      "The Recall is:  0.9850\n",
      "The F1 score is:  0.9712\n",
      "The Matthews correlation coefficient is:  0.8091\n",
      "Confusion matrix:\n",
      " [[ 186   55]\n",
      " [  19 1247]]\n",
      "Cross-validation scores: [0.86870897 0.94967177 0.96280088 0.97155361 0.96491228 0.96929825\n",
      " 0.9254386  0.95833333 0.96491228 0.94736842]\n",
      "Average score:0.9483\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Replace NaN values with mean value of k-nearest neighbors using KNNImputer\n",
    "knn_imputer = KNNImputer()\n",
    "df_imputed_knn = knn_imputer.fit_transform(X)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_imputed_knn, df_encoded_classes, test_size=0.33)\n",
    "\n",
    "# Create a logistic regression model\n",
    "clf = LogisticRegression(max_iter=10000)\n",
    "\n",
    "# Train the model on the training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model using various metrics\n",
    "classification_scores(y_test, y_pred)\n",
    "\n",
    "scores = cross_val_score(clf, df_imputed_knn, df_encoded_classes, cv=10)\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(\"Average score:{:.4f}\".format(scores.mean()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Iterative Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Precision is:  0.9583\n",
      "The Recall is:  0.9849\n",
      "The F1 score is:  0.9714\n",
      "The Matthews correlation coefficient is:  0.8165\n",
      "Confusion matrix:\n",
      " [[ 194   54]\n",
      " [  19 1240]]\n",
      "Cross-validation scores: [0.87089716 0.94748359 0.96061269 0.97155361 0.9627193  0.96710526\n",
      " 0.92105263 0.95833333 0.96491228 0.94517544]\n",
      "Average score:0.9470\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Replace NaN values with mean value of k-nearest neighbors using KNNImputer\n",
    "iter_imputer = IterativeImputer(random_state = 0)\n",
    "df_imputed_iter = iter_imputer.fit_transform(X)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_imputed_iter, df_encoded_classes, test_size=0.33)\n",
    "\n",
    "# Create a logistic regression model\n",
    "clf = LogisticRegression(max_iter=10000)\n",
    "\n",
    "# Train the model on the training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model using various metrics\n",
    "classification_scores(y_test, y_pred)\n",
    "\n",
    "scores = cross_val_score(clf, df_imputed_iter, df_encoded_classes, cv=10)\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(\"Average score:{:.4f}\".format(scores.mean()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Imputers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df_encoded_classes, test_size=0.33, random_state=0)\n",
    "\n",
    "clf = LogisticRegression(random_state=42, max_iter=10000) \n",
    "\n",
    "# Define the imputers to test\n",
    "imputers = [\n",
    "    ('SimpleImputer', SimpleImputer(strategy='mean')),\n",
    "    ('SimpleImputer', SimpleImputer(strategy='median')),\n",
    "    ('KNNImputer', KNNImputer()),\n",
    "    ('IterativeImputer', IterativeImputer())\n",
    "]\n",
    "\n",
    "# Define the metrics to evaluate\n",
    "metrics = [\n",
    "    ('Precision', precision_score),\n",
    "    ('Recall', recall_score),\n",
    "    ('F1 Score', f1_score),\n",
    "    ('MCC', matthews_corrcoef)\n",
    "]\n",
    "\n",
    "# Evaluate each imputer on the dataset\n",
    "results = {}\n",
    "for imputer_name, imputer in imputers:\n",
    "    X_train_imputed = imputer.fit_transform(X_train)\n",
    "    X_test_imputed = imputer.transform(X_test)\n",
    "    results[imputer_name] = {}\n",
    "    for metric_name, metric_func in metrics:\n",
    "        y_pred = clf.fit(X_train_imputed, y_train).predict(X_test_imputed)\n",
    "        score = metric_func(y_test, y_pred)\n",
    "        results[imputer_name][metric_name] = score\n",
    "\n",
    "# Plot the results as histograms\n",
    "fig, axs = plt.subplots(nrows=1, ncols=len(imputers), figsize=(15, 4))\n",
    "for j, (imputer_name, _) in enumerate(imputers):\n",
    "    metric_names = [metric_name for metric_name, _ in metrics]\n",
    "    metric_scores = [results[imputer_name][metric_name] for metric_name, _ in metrics]\n",
    "    axs[j].bar(metric_names, metric_scores)\n",
    "    axs[j].set_title(imputer_name)\n",
    "    axs[j].set_ylim([0.7, 1.0])\n",
    "    axs[j].grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for: MinMaxScaler\n",
      "Accuracy: 0.9230\n",
      "Precision: 0.9214\n",
      "Recall: 0.9920\n",
      "Confusion Matrix:\n",
      "[[ 149  106]\n",
      " [  10 1242]]\n",
      "\n",
      "Results for: StandardScaler\n",
      "Accuracy: 0.9542\n",
      "Precision: 0.9575\n",
      "Recall: 0.9888\n",
      "Confusion Matrix:\n",
      "[[ 200   55]\n",
      " [  14 1238]]\n",
      "\n",
      "Results for: Normalizer\n",
      "Accuracy: 0.8719\n",
      "Precision: 0.8669\n",
      "Recall: 0.9992\n",
      "Confusion Matrix:\n",
      "[[  63  192]\n",
      " [   1 1251]]\n",
      "\n",
      "Results for: PowerTransformer\n",
      "Accuracy: 0.9396\n",
      "Precision: 0.9490\n",
      "Recall: 0.9800\n",
      "Confusion Matrix:\n",
      "[[ 189   66]\n",
      " [  25 1227]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer, PowerTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# Using a simple imputer TODO use the best\n",
    "simple_imputer = SimpleImputer(strategy = \"median\")\n",
    "df_imputed_simple = simple_imputer.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_imputed_simple, y, test_size=0.33)\n",
    "X_train.shape, X_test.shape\n",
    "\n",
    "scalers = [(MinMaxScaler(),\"MinMaxScaler\"), (StandardScaler(),\"StandardScaler\"), (Normalizer(),\"Normalizer\"), (PowerTransformer(),\"PowerTransformer\")]\n",
    "\n",
    "for scaler,name in scalers:\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    clf = LogisticRegression(max_iter=10000)\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, pos_label='RB')\n",
    "    recall = recall_score(y_test, y_pred, pos_label='RB')\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Results for:\", name)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{cm}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
